{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBhavBZ-zALa"
   },
   "source": [
    "#Perceptron - Pima Indians Diabetes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6Z86nhs0Npu"
   },
   "source": [
    "##Prepare Packages and Google Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wL8d2Z9Oyj6K"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lc0OsATM1Lun",
    "outputId": "58f76d83-ea55-45a4-b268-23567fe4d1b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#mount the google drive to access the data \n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSqnkrUQ0ViI"
   },
   "source": [
    "##Initialise Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1U6ZwQuIK32"
   },
   "source": [
    "###Real World Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "hog5j8E80Y3Y",
    "outputId": "6fa66d33-ed64-4ef1-f73f-904c530bf9e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6HIj33v_7VUN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.234415</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.427136</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396423</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347243</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.418778</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.352941  0.743719  0.590164  0.353535  0.000000  0.500745  0.234415   \n",
       "1  0.058824  0.427136  0.540984  0.292929  0.000000  0.396423  0.116567   \n",
       "2  0.470588  0.919598  0.524590  0.000000  0.000000  0.347243  0.253629   \n",
       "3  0.058824  0.447236  0.540984  0.232323  0.111111  0.418778  0.038002   \n",
       "4  0.000000  0.688442  0.327869  0.353535  0.198582  0.642325  0.943638   \n",
       "\n",
       "          7  \n",
       "0  0.483333  \n",
       "1  0.166667  \n",
       "2  0.183333  \n",
       "3  0.000000  \n",
       "4  0.200000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove classification column\n",
    "variables = data.drop(\"Outcome\", axis = 1)\n",
    "#Create new data frame with classification column\n",
    "classification = data[\"Outcome\"]\n",
    "#Normalize data\n",
    "variables = MinMaxScaler().fit_transform(variables)\n",
    "#Turn Data back into a dataframe\n",
    "variables = pd.DataFrame(variables)\n",
    "variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z6O3nVtV9H9D"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZAXpxMbf4s9y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8)\n",
      "(154, 8)\n",
      "(614,)\n",
      "(154,)\n"
     ]
    }
   ],
   "source": [
    "#Split dataset into test and training sets\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(variables, classification, test_size=0.2, random_state=0)\n",
    "#Check the size of the training and testing sets\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4A2t-daHrjhu"
   },
   "outputs": [],
   "source": [
    "#Convert dataset into numpy arrays\n",
    "train_X = np.array(train_X)\n",
    "test_X = np.array(test_X)\n",
    "train_Y = np.array(train_Y)\n",
    "test_Y = np.array(test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G448pFaUIRvO"
   },
   "source": [
    "###Toy Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09seUU46IjZm"
   },
   "source": [
    "For the toy dataset the iris dataset was used with data some data preparation demonstrated by Jun Li in his week 10 demonstration (https://colab.research.google.com/drive/1sdyzxla7RjCCrRWmlHVUXnIRtfyK4gCs?usp=sharing). The goal of the dataset is to simplify the iris dataset into a binary dataset with only 100 data points in order for the Perceptron to be tested on an easy data set to validate the algorithm works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dvK0xao-IfP-"
   },
   "outputs": [],
   "source": [
    "#Load the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_iris()\n",
    "#Minimise the X dataset into 2 data attributes and reduce the dataset to only 100 samples\n",
    "X = data['data'][:100, :2]\n",
    "#Take the first 100 target samples to match with the X attributes\n",
    "y = data['target'][:100]\n",
    "#Split the data set into training and testing set with 33% going to the test side\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "js52_nrj1PqG"
   },
   "source": [
    "##Design the Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6c6g6gujMi4l"
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "  #Create the constructor for the Perceptron and initialise parameters\n",
    "  def __init__(self, learning_rate = 0.1, epochs = 10):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.epochs = epochs\n",
    "    self.weights = None\n",
    "    self.bias = None\n",
    "  \n",
    "  #create an activation function\n",
    "  def activation_func(self, x):\n",
    "    #if x is greater or equal to 0 return 1 otherwise return 0 meaning if it is activated or not\n",
    "    return 1 if x >= self.bias else 0\n",
    "  \n",
    "  #create the weighted sum for the hypothesis space\n",
    "  def weighted_sum(self, x):\n",
    "    #transpose of weights times the data samples plus the bias\n",
    "    return np.dot(x, self.weights) + self.bias\n",
    "\n",
    "  #Fit the data to the model\n",
    "  def fit(self, X, y):\n",
    "    #Initialise features\n",
    "    #make the weights initially all zero based on he number of features in the data\n",
    "    self.weights = np.zeros(X.shape[1])\n",
    "    #initialise the bias to be 0\n",
    "    self.bias = 0\n",
    "    #initialise the count to be 0\n",
    "    count = 0\n",
    "    #covert labelled data into a numpy array for processing\n",
    "    y_array = np.array(y)\n",
    "\n",
    "    while(count <= self.epochs):\n",
    "      #initialise an array to append the current predicted values to\n",
    "      predict_array = []\n",
    "      for i, x in enumerate(X):\n",
    "        #calculate predicted values\n",
    "        #print(self.weights)\n",
    "        #print(x)\n",
    "        linear_calc = self.weighted_sum(x)\n",
    "        predicted_value = self.activation_func(linear_calc)\n",
    "        #append predictins for the current epoch into an array\n",
    "        predict_array.append(predicted_value)\n",
    "\n",
    "        # print(\"linear calc:\", linear_calc)\n",
    "        # print(\"real value:\", y_array[i])\n",
    "        # print(\"predicted_value:\", predicted_value)\n",
    "        \n",
    "        #Update the wegihts and biases based on an update rule\n",
    "        #Update rule stating that if the predicted value is false but the real value is true increase the weights and decrease the bias based on the learning rate\n",
    "        if y_array[i] == 1 and predicted_value == 0:\n",
    "          self.weights = self.weights + self.learning_rate * x\n",
    "          self.bias = self.bias - self.learning_rate\n",
    "        #Update rule stating that if the predicted value is true but the real value is false increase the bias and decrease the weights based on the learning rate\n",
    "        elif y_array[i] == 0 and predicted_value == 1:\n",
    "          self.weights = self.weights - self.learning_rate * x\n",
    "          self.bias = self.bias + self.learning_rate\n",
    "        \n",
    "        # print(\"weights\" , self.weights)\n",
    "        # print(\"bias\", self.bias)\n",
    "      #calculate the accuracy of the current epoch \n",
    "      curr_accuracy = accuracy_score(y_array, predict_array)\n",
    "      print(\"No. Epoch:\", count, \",\", \"Accuracy:\", curr_accuracy)\n",
    "      #increase the count\n",
    "      count += 1\n",
    "  \n",
    "  #create the predict function\n",
    "  def predict(self, X):\n",
    "    #initialise an array to hold the predicted results\n",
    "    Y_prediction = []\n",
    "    for x in X:\n",
    "      #calculate the approximation\n",
    "      linear_calc = self.weighted_sum(x)\n",
    "      #determine whether the perceptron will be activated based on the calculated approximation\n",
    "      prediction = self.activation_func(linear_calc)\n",
    "      #append the predicted results to the array and return the array\n",
    "      Y_prediction.append(prediction)\n",
    "    return np.array(Y_prediction)\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfJipOhlJ5db"
   },
   "source": [
    "##Test the Perceptron on the Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qEROK8_9J9Lw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. Epoch: 0 , Accuracy: 0.6625\n",
      "No. Epoch: 1 , Accuracy: 0.85\n",
      "No. Epoch: 2 , Accuracy: 0.6875\n",
      "No. Epoch: 3 , Accuracy: 0.8625\n",
      "No. Epoch: 4 , Accuracy: 0.9\n",
      "No. Epoch: 5 , Accuracy: 0.85\n",
      "No. Epoch: 6 , Accuracy: 0.9\n",
      "No. Epoch: 7 , Accuracy: 0.8375\n",
      "No. Epoch: 8 , Accuracy: 0.9\n",
      "No. Epoch: 9 , Accuracy: 0.9\n",
      "No. Epoch: 10 , Accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "#construct perceptron\n",
    "perceptron = Perceptron()\n",
    "#fit data to the perceptron\n",
    "perceptron.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ccIPHWWmKKS-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [1 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0]\n",
      "actual outcomes [1 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#run the perceptron's predict function on the test data\n",
    "pred = perceptron.predict(X_test)\n",
    "#show the predicted values and actual values\n",
    "print(\"predictions\", pred)\n",
    "print(\"actual outcomes\", y_test)\n",
    "#display the accuracy of the model on the toy dataset\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDK0Y_yq1Tqj"
   },
   "source": [
    "##Train the Perecptron on the Real-World Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dnd3TPviai4V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. Epoch: 0 , Accuracy: 0.5651465798045603\n",
      "No. Epoch: 1 , Accuracy: 0.5504885993485342\n",
      "No. Epoch: 2 , Accuracy: 0.5456026058631922\n",
      "No. Epoch: 3 , Accuracy: 0.5407166123778502\n",
      "No. Epoch: 4 , Accuracy: 0.5439739413680782\n",
      "No. Epoch: 5 , Accuracy: 0.5570032573289903\n",
      "No. Epoch: 6 , Accuracy: 0.5456026058631922\n",
      "No. Epoch: 7 , Accuracy: 0.5667752442996743\n",
      "No. Epoch: 8 , Accuracy: 0.5618892508143323\n",
      "No. Epoch: 9 , Accuracy: 0.5651465798045603\n",
      "No. Epoch: 10 , Accuracy: 0.5456026058631922\n",
      "No. Epoch: 11 , Accuracy: 0.5472312703583062\n",
      "No. Epoch: 12 , Accuracy: 0.5521172638436482\n",
      "No. Epoch: 13 , Accuracy: 0.5553745928338762\n",
      "No. Epoch: 14 , Accuracy: 0.5570032573289903\n",
      "No. Epoch: 15 , Accuracy: 0.5684039087947883\n",
      "No. Epoch: 16 , Accuracy: 0.5732899022801303\n",
      "No. Epoch: 17 , Accuracy: 0.5716612377850163\n",
      "No. Epoch: 18 , Accuracy: 0.5586319218241043\n",
      "No. Epoch: 19 , Accuracy: 0.5618892508143323\n",
      "No. Epoch: 20 , Accuracy: 0.5602605863192183\n",
      "No. Epoch: 21 , Accuracy: 0.5423452768729642\n",
      "No. Epoch: 22 , Accuracy: 0.5390879478827362\n",
      "No. Epoch: 23 , Accuracy: 0.5700325732899023\n",
      "No. Epoch: 24 , Accuracy: 0.5667752442996743\n",
      "No. Epoch: 25 , Accuracy: 0.5504885993485342\n",
      "No. Epoch: 26 , Accuracy: 0.5504885993485342\n",
      "No. Epoch: 27 , Accuracy: 0.5423452768729642\n",
      "No. Epoch: 28 , Accuracy: 0.5358306188925082\n",
      "No. Epoch: 29 , Accuracy: 0.5570032573289903\n",
      "No. Epoch: 30 , Accuracy: 0.5423452768729642\n",
      "No. Epoch: 31 , Accuracy: 0.5618892508143323\n",
      "No. Epoch: 32 , Accuracy: 0.5570032573289903\n",
      "No. Epoch: 33 , Accuracy: 0.5570032573289903\n",
      "No. Epoch: 34 , Accuracy: 0.5684039087947883\n",
      "No. Epoch: 35 , Accuracy: 0.5781758957654723\n",
      "No. Epoch: 36 , Accuracy: 0.5521172638436482\n",
      "No. Epoch: 37 , Accuracy: 0.5586319218241043\n",
      "No. Epoch: 38 , Accuracy: 0.5602605863192183\n",
      "No. Epoch: 39 , Accuracy: 0.5439739413680782\n",
      "No. Epoch: 40 , Accuracy: 0.5635179153094463\n",
      "No. Epoch: 41 , Accuracy: 0.5390879478827362\n",
      "No. Epoch: 42 , Accuracy: 0.5732899022801303\n",
      "No. Epoch: 43 , Accuracy: 0.5407166123778502\n",
      "No. Epoch: 44 , Accuracy: 0.5439739413680782\n",
      "No. Epoch: 45 , Accuracy: 0.5732899022801303\n",
      "No. Epoch: 46 , Accuracy: 0.5602605863192183\n",
      "No. Epoch: 47 , Accuracy: 0.5602605863192183\n",
      "No. Epoch: 48 , Accuracy: 0.5407166123778502\n",
      "No. Epoch: 49 , Accuracy: 0.5765472312703583\n",
      "No. Epoch: 50 , Accuracy: 0.5667752442996743\n",
      "No. Epoch: 51 , Accuracy: 0.5667752442996743\n",
      "No. Epoch: 52 , Accuracy: 0.5456026058631922\n",
      "No. Epoch: 53 , Accuracy: 0.5684039087947883\n",
      "No. Epoch: 54 , Accuracy: 0.5651465798045603\n",
      "No. Epoch: 55 , Accuracy: 0.5439739413680782\n",
      "No. Epoch: 56 , Accuracy: 0.5570032573289903\n",
      "No. Epoch: 57 , Accuracy: 0.5423452768729642\n",
      "No. Epoch: 58 , Accuracy: 0.5553745928338762\n",
      "No. Epoch: 59 , Accuracy: 0.5537459283387622\n",
      "No. Epoch: 60 , Accuracy: 0.5635179153094463\n",
      "No. Epoch: 61 , Accuracy: 0.5456026058631922\n",
      "No. Epoch: 62 , Accuracy: 0.5553745928338762\n",
      "No. Epoch: 63 , Accuracy: 0.5504885993485342\n",
      "No. Epoch: 64 , Accuracy: 0.5456026058631922\n",
      "No. Epoch: 65 , Accuracy: 0.5537459283387622\n",
      "No. Epoch: 66 , Accuracy: 0.5293159609120521\n",
      "No. Epoch: 67 , Accuracy: 0.5537459283387622\n",
      "No. Epoch: 68 , Accuracy: 0.5618892508143323\n",
      "No. Epoch: 69 , Accuracy: 0.5700325732899023\n",
      "No. Epoch: 70 , Accuracy: 0.5749185667752443\n",
      "No. Epoch: 71 , Accuracy: 0.5423452768729642\n",
      "No. Epoch: 72 , Accuracy: 0.5521172638436482\n",
      "No. Epoch: 73 , Accuracy: 0.5570032573289903\n",
      "No. Epoch: 74 , Accuracy: 0.5390879478827362\n",
      "No. Epoch: 75 , Accuracy: 0.5635179153094463\n",
      "No. Epoch: 76 , Accuracy: 0.5651465798045603\n",
      "No. Epoch: 77 , Accuracy: 0.5618892508143323\n",
      "No. Epoch: 78 , Accuracy: 0.5472312703583062\n",
      "No. Epoch: 79 , Accuracy: 0.5293159609120521\n",
      "No. Epoch: 80 , Accuracy: 0.5732899022801303\n",
      "No. Epoch: 81 , Accuracy: 0.5618892508143323\n",
      "No. Epoch: 82 , Accuracy: 0.5309446254071661\n",
      "No. Epoch: 83 , Accuracy: 0.5586319218241043\n",
      "No. Epoch: 84 , Accuracy: 0.5635179153094463\n",
      "No. Epoch: 85 , Accuracy: 0.5553745928338762\n",
      "No. Epoch: 86 , Accuracy: 0.5456026058631922\n",
      "No. Epoch: 87 , Accuracy: 0.5439739413680782\n",
      "No. Epoch: 88 , Accuracy: 0.5553745928338762\n",
      "No. Epoch: 89 , Accuracy: 0.5521172638436482\n",
      "No. Epoch: 90 , Accuracy: 0.5553745928338762\n",
      "No. Epoch: 91 , Accuracy: 0.5570032573289903\n",
      "No. Epoch: 92 , Accuracy: 0.5374592833876222\n",
      "No. Epoch: 93 , Accuracy: 0.5521172638436482\n",
      "No. Epoch: 94 , Accuracy: 0.5472312703583062\n",
      "No. Epoch: 95 , Accuracy: 0.5423452768729642\n",
      "No. Epoch: 96 , Accuracy: 0.5667752442996743\n",
      "No. Epoch: 97 , Accuracy: 0.5423452768729642\n",
      "No. Epoch: 98 , Accuracy: 0.5537459283387622\n",
      "No. Epoch: 99 , Accuracy: 0.5488599348534202\n",
      "No. Epoch: 100 , Accuracy: 0.5553745928338762\n"
     ]
    }
   ],
   "source": [
    "#construct perceptron with 100 epochs instead of 10\n",
    "perceptron = Perceptron(0.1, 100)\n",
    "#fit data to the perceptron\n",
    "perceptron.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKQzZz8s1aSy"
   },
   "source": [
    "##Evaluation of the Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SAoVmcDl0gxh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run the perceptron's predict function on the test data\n",
    "pred = perceptron.predict(test_X)\n",
    "#check the shape of the prediction array to ensure the prediction function produced the right format\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QqDvlRaAf-8r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "actual outcomes [1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 1 0 0]\n",
      "confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[104,   3],\n",
       "       [ 44,   3]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare the predicted results with the true results \n",
    "print(\"predictions\", pred)\n",
    "print(\"actual outcomes\", test_Y)\n",
    "print(\"confusion matrix:\")\n",
    "confusion_matrix(test_Y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MK7nXXPsI903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6948051948051948\n",
      "Precision: 0.5\n",
      "F1 score: 0.11320754716981131\n",
      "Area Under the Curve Score: 0.5178962020282362\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(test_Y, pred))\n",
    "print(\"Precision:\", precision_score(test_Y, pred))\n",
    "print(\"F1 score:\", f1_score(test_Y, pred))\n",
    "print(\"Area Under the Curve Score:\", roc_auc_score(test_Y, pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
