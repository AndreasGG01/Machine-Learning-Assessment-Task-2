{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMEIBopri/Ka9f9Ha2HEJaG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Perceptron - Pima Indians Diabetes Classification"],"metadata":{"id":"gBhavBZ-zALa"}},{"cell_type":"markdown","source":["##Prepare Packages and Google Collab"],"metadata":{"id":"Y6Z86nhs0Npu"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"wL8d2Z9Oyj6K","executionInfo":{"status":"ok","timestamp":1665808587206,"user_tz":-660,"elapsed":664,"user":{"displayName":"Andreas GG","userId":"11884547753043419554"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, roc_auc_score"]},{"cell_type":"code","source":["#mount the google drive to access the data \n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lc0OsATM1Lun","executionInfo":{"status":"ok","timestamp":1665808609111,"user_tz":-660,"elapsed":20163,"user":{"displayName":"Andreas GG","userId":"11884547753043419554"}},"outputId":"58f76d83-ea55-45a4-b268-23567fe4d1b6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["##Initialise Dataset"],"metadata":{"id":"KSqnkrUQ0ViI"}},{"cell_type":"markdown","source":["###Real World Dataset"],"metadata":{"id":"p1U6ZwQuIK32"}},{"cell_type":"code","source":["#Load Dataset\n","data = pd.read_csv('diabetes.csv')\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"hog5j8E80Y3Y","executionInfo":{"status":"error","timestamp":1665808662054,"user_tz":-660,"elapsed":324,"user":{"displayName":"Andreas GG","userId":"11884547753043419554"}},"outputId":"6fa66d33-ed64-4ef1-f73f-904c530bf9e8"},"execution_count":7,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-3324604878a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diabetes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'diabetes.csv'"]}]},{"cell_type":"code","source":["#Remove classification column\n","variables = data.drop(\"Outcome\", axis = 1)\n","#Create new data frame with classification column\n","classification = data[\"Outcome\"]\n","#Normalize data\n","variables = MinMaxScaler().fit_transform(variables)\n","#Turn Data back into a dataframe\n","variables = pd.DataFrame(variables)\n","variables.head()"],"metadata":{"id":"6HIj33v_7VUN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classification.head()"],"metadata":{"id":"z6O3nVtV9H9D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Split dataset into test and training sets\n","train_X, test_X, train_Y, test_Y = train_test_split(variables, classification, test_size=0.2, random_state=0)\n","#Check the size of the training and testing sets\n","print(train_X.shape)\n","print(test_X.shape)\n","print(train_Y.shape)\n","print(test_Y.shape)"],"metadata":{"id":"ZAXpxMbf4s9y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Convert dataset into numpy arrays\n","train_X = np.array(train_X)\n","test_X = np.array(test_X)\n","train_Y = np.array(train_Y)\n","test_Y = np.array(test_Y)"],"metadata":{"id":"4A2t-daHrjhu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Toy Dataset"],"metadata":{"id":"G448pFaUIRvO"}},{"cell_type":"markdown","source":["For the toy dataset the iris dataset was used with data some data preparation demonstrated by Jun Li in his week 10 demonstration (https://colab.research.google.com/drive/1sdyzxla7RjCCrRWmlHVUXnIRtfyK4gCs?usp=sharing). The goal of the dataset is to simplify the iris dataset into a binary dataset with only 100 data points in order for the Perceptron to be tested on an easy data set to validate the algorithm works as expected"],"metadata":{"id":"09seUU46IjZm"}},{"cell_type":"code","source":["#Load the iris dataset\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","data = load_iris()\n","#Minimise the X dataset into 2 data attributes and reduce the dataset to only 100 samples\n","X = data['data'][:100, :2]\n","#Take the first 100 target samples to match with the X attributes\n","y = data['target'][:100]\n","#Split the data set into training and testing set with 33% going to the test side\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"dvK0xao-IfP-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Design the Perceptron"],"metadata":{"id":"js52_nrj1PqG"}},{"cell_type":"code","source":["class Perceptron:\n","  #Create the constructor for the Perceptron and initialise parameters\n","  def __init__(self, learning_rate = 0.1, epochs = 10):\n","    self.learning_rate = learning_rate\n","    self.epochs = epochs\n","    self.weights = None\n","    self.bias = None\n","  \n","  #create an activation function\n","  def activation_func(self, x):\n","    #if x is greater or equal to 0 return 1 otherwise return 0 meaning if it is activated or not\n","    return 1 if x >= self.bias else 0\n","  \n","  #create the weighted sum for the hypothesis space\n","  def weighted_sum(self, x):\n","    #transpose of weights times the data samples plus the bias\n","    return np.dot(x, self.weights) + self.bias\n","\n","  #Fit the data to the model\n","  def fit(self, X, y):\n","    #Initialise features\n","    #make the weights initially all zero based on he number of features in the data\n","    self.weights = np.zeros(X.shape[1])\n","    #initialise the bias to be 0\n","    self.bias = 0\n","    #initialise the count to be 0\n","    count = 0\n","    #covert labelled data into a numpy array for processing\n","    y_array = np.array(y)\n","\n","    while(count <= self.epochs):\n","      #initialise an array to append the current predicted values to\n","      predict_array = []\n","      for i, x in enumerate(X):\n","        #calculate predicted values\n","        #print(self.weights)\n","        #print(x)\n","        linear_calc = self.weighted_sum(x)\n","        predicted_value = self.activation_func(linear_calc)\n","        #append predictins for the current epoch into an array\n","        predict_array.append(predicted_value)\n","\n","        # print(\"linear calc:\", linear_calc)\n","        # print(\"real value:\", y_array[i])\n","        # print(\"predicted_value:\", predicted_value)\n","        \n","        #Update the wegihts and biases based on an update rule\n","        #Update rule stating that if the predicted value is false but the real value is true increase the weights and decrease the bias based on the learning rate\n","        if y_array[i] == 1 and predicted_value == 0:\n","          self.weights = self.weights + self.learning_rate * x\n","          self.bias = self.bias - self.learning_rate\n","        #Update rule stating that if the predicted value is true but the real value is false increase the bias and decrease the weights based on the learning rate\n","        elif y_array[i] == 0 and predicted_value == 1:\n","          self.weights = self.weights - self.learning_rate * x\n","          self.bias = self.bias + self.learning_rate\n","        \n","        # print(\"weights\" , self.weights)\n","        # print(\"bias\", self.bias)\n","      #calculate the accuracy of the current epoch \n","      curr_accuracy = accuracy_score(y_array, predict_array)\n","      print(\"No. Epoch:\", count, \",\", \"Accuracy:\", curr_accuracy)\n","      #increase the count\n","      count += 1\n","  \n","  #create the predict function\n","  def predict(self, X):\n","    #initialise an array to hold the predicted results\n","    Y_prediction = []\n","    for x in X:\n","      #calculate the approximation\n","      linear_calc = self.weighted_sum(x)\n","      #determine whether the perceptron will be activated based on the calculated approximation\n","      prediction = self.activation_func(linear_calc)\n","      #append the predicted results to the array and return the array\n","      Y_prediction.append(prediction)\n","    return np.array(Y_prediction)\n","  \n","\n"],"metadata":{"id":"6c6g6gujMi4l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Test the Perceptron on the Toy Dataset"],"metadata":{"id":"lfJipOhlJ5db"}},{"cell_type":"code","source":["#construct perceptron\n","perceptron = Perceptron()\n","#fit data to the perceptron\n","perceptron.fit(X_train, y_train)"],"metadata":{"id":"qEROK8_9J9Lw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#run the perceptron's predict function on the test data\n","pred = perceptron.predict(X_test)\n","#show the predicted values and actual values\n","print(\"predictions\", pred)\n","print(\"actual outcomes\", y_test)\n","#display the accuracy of the model on the toy dataset\n","print(\"Accuracy:\", accuracy_score(y_test, pred))"],"metadata":{"id":"ccIPHWWmKKS-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Train the Perecptron on the Real-World Dataset"],"metadata":{"id":"wDK0Y_yq1Tqj"}},{"cell_type":"code","source":["#construct perceptron with 100 epochs instead of 10\n","perceptron = Perceptron(0.1, 100)\n","#fit data to the perceptron\n","perceptron.fit(train_X, train_Y)"],"metadata":{"id":"dnd3TPviai4V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Evaluation of the Perceptron\n"],"metadata":{"id":"LKQzZz8s1aSy"}},{"cell_type":"code","source":["#run the perceptron's predict function on the test data\n","pred = perceptron.predict(test_X)\n","#check the shape of the prediction array to ensure the prediction function produced the right format\n","pred.shape"],"metadata":{"id":"SAoVmcDl0gxh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compare the predicted results with the true results \n","print(\"predictions\", pred)\n","print(\"actual outcomes\", test_Y)\n","print(\"confusion matrix:\")\n","confusion_matrix(test_Y, pred)"],"metadata":{"id":"QqDvlRaAf-8r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Accuracy:\", accuracy_score(test_Y, pred))\n","print(\"Precision:\", precision_score(test_Y, pred))\n","print(\"F1 score:\", f1_score(test_Y, pred))\n","print(\"Area Under the Curve Score:\", roc_auc_score(test_Y, pred))"],"metadata":{"id":"MK7nXXPsI903"},"execution_count":null,"outputs":[]}]}